### Virtual Machine Load Balancing with Kubernetes Networking Resources

High Availability (HA) with Hypervisors:
- HA means keeping services running, even if there are failures.
- In traditional hypervisors like VMware vSphere, HA means: Automatically restarting VMs on other hosts if one fails. But this often needs manual configuration for clustering, app monitoring, and load balancing.

Fencing Hosts for VM Integrity:
- You must prevent a VM from running on two hosts at once (split-brain), which could cause disk corruption and data loss.
- Fencing = isolating or powering off a failed host before moving its workloads.
  - Usually done via out-of-band agents (like iDRAC, iLO).
  - Ensures the VM is fully stopped on the old host before it’s restarted on another.

Load Balancing with Hypervisors:
- Load balancing = spreading incoming traffic across VMs to avoid bottlenecks.
- Hypervisors don’t provide built-in traffic load balancing for VMs. You need to add a load balancer and configure:
  - Health checks (readiness/liveness probes),
  - Fencing
  - Node actions like restarts.
 
Kubernetes + KubeVirt for Managing VMs:
- A tool that lets you run VMs alongside containers in a Kubernetes cluster.
- Uses KVM (Kernel-based Virtual Machine) inside Kubernetes pods.
- Provides hypervisor-like features: Live migration and Active resource balancing.

Kubernetes Features Enabling High Availability:
- VM Run Strategies: Controls how VMs restart if deleted or fail. spec.running or spec.runStrategy in the VMI (VirtualMachineInstance) resource defines the behavior.
- Readiness & Liveness Probes:
  - Readiness probe: Checks if VM/app is ready to receive traffic. If it fails, the service won’t route requests to it.
  - Liveness probe: Checks if the app is healthy. If it fails, the VM is recreated.
- Watchdog Devices: A watchdog runs inside the VM to monitor the OS state. Does not monitor app health. Acts based on the run strategy.
- Live Migration: Move a VM from one node to another without shutting it down, e.g., for maintenance.
- Machine Health Checks: Automatically detect and recover from host/node failures. Kubernetes deletes and recreates nodes that are NotReady.
- Fencing Nodes: If a node goes bad, Kubernetes removes the associated Machine resource, which deletes and recreates the node. Prevents duplicate VMs or corruption.

Load Balancing in Kubernetes:
- LoadBalancer service: Exposes a Kubernetes app (including a VM) externally with a unique IP.
- Cloud providers (like AWS, GCP) offer built-in load balancers.
- On bare metal or hypervisor-based clusters, you can use: MetalLB — an open-source load balancer for Kubernetes.

Sticky Sessions (Session Affinity): 
- Sticky sessions ensure traffic from one client goes to the same backend.
- Important for stateful apps (e.g., shopping carts).

Configuring Route Statefulness in OpenShift:
- OpenShift supports sticky sessions via cookies in its Ingress controller.
  - Ingress controller picks a backend (pod/VM) and sets a cookie.
  - Client sends the cookie back with each request.
  - The controller routes traffic to the same backend based on the cookie.
- You can customize the cookie name using an annotation in the Route
```yaml
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  annotations:
    router.openshift.io/cookie_name: "hello"
```
