### Survive Node Failure

VM Scheduling: 
- OpenShift uses its built-in scheduler to place VMs on healthy nodes, following rules like:
  - Node Selectors
  - Affinity/Anti-Affinity
  - Taints and Tolerations
 
Scheduler Profiles:
- These control how OpenShift spreads pods (and VMs) across nodes:
  - LowNodeUtilization: Evenly spreads workloads across all nodes.
  - HighNodeUtilization: Packs workloads tightly on fewer nodes.
  - NoScoring: Prioritizes scheduling speed over optimization.
 
Eviction Strategies:
- When a node fails or is drained (for maintenance), eviction strategies decide what happens to VMs:
  - LiveMigrate (default): VM is live migrated to a new node. Requires shared storage (RWX PVC).
  - LiveMigrateIfPossible: Tries to migrate; if not possible, terminates the VM.
  - None: VM is not migrated. Behavior depends on runStrategy.
 
Node Failures & Detection:
- Detected via virt-handler heartbeat and Kubernetes health checks.
- Might take up to 5 minutes to recognize a failed node.

Node Failures & Detection:
- Detected via virt-handler heartbeat and Kubernetes health checks.
- Might take up to 5 minutes to recognize a failed node.
- VMs are migrated or rescheduled based on:  Scheduling rules & Eviction strategies

Monitoring and Health Checks:
- Watchdog Device: Monitors the VM's guest OS. If the guest OS hangs, you can configure:
  - poweroff – Power off and reboot if configured
  - reset – Hard reboot
  - shutdown – Graceful shutdown
- Application Health Checks
  - Readiness Probes – Checks if the app is ready to serve traffic.
  - Liveness Probes – Checks if the app is still alive.
 
Automated Recovery Tools:
- Machine Health Check (MHC): For bare-metal IPI clusters, this automatically
  - Detects failed nodes
  - Drains them
  - Reboots or replaces them
  - Reschedules VMs based on strategy
- Limitations: Works only for nodes created via MachineSet. Must not exceed maxUnhealthy threshold

Power-Based Remediation (Power Fencing):
- Instead of reprovisioning, just power cycle the faulty node.
- Requires BMC (Baseboard Management Controller)
- Faster recovery, less data loss

Self Node Remediation Operator:
- Used in non-IPI bare-metal clusters.
- Reboots a failed node automatically
- Helps reduce downtime for apps using ReadWriteOnce PVCs
- Works with MachineHealthCheck

Manual Recovery Steps (If no auto-recovery is set up): 
- Cordoning the node: `oc adm cordon worker01`
- Drain the node (moves VMs/pods off the node): `oc adm drain worker01 --ignore-daemonsets --delete-emptydir-data --force`
- Delete the node: `oc delete node worker01`
- Verify VMs are rescheduled: `oc get vmis --all-namespaces`
- If pods/VMs are not part of a replica set or don't have a runStrategy: Always, they might not be rescheduled automatically.

Disaster Recovery Solutions:
- Metro-DR: Synchronous replication between two nearby data centers. Ensures zero data loss.
- Regional-DR: Asynchronous replication to a distant region. Handles regional failures with minimal downtime.
- Uses: VolSync for volume replication. OpenShift GitOps + RHACM for managing application state across clusters
